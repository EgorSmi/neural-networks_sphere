{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb7bc1c",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9176c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "from tqdm.autonotebook import tqdm\n",
    "import progressbar\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f2a30",
   "metadata": {},
   "source": [
    "## Первая модель - Oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea09e3e",
   "metadata": {},
   "source": [
    "## Загрузка данных и предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaababd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/stihi.json', 'rt', encoding='UTF-8') as f:\n",
    "    stih_d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stihs = []\n",
    "for key in stih_d.keys():\n",
    "    mas = [text.replace(\".\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"-\", \"\").replace(\"\\\"\", \"\").replace(\";\", \"\").replace(\"!\", \"\").replace(\"#\", \"\").replace(\"?\", \"\").lower().split() for text in stih_d[key]]\n",
    "    all_stihs.extend(mas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a33fe69",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, sentences):\n",
    "        all_characters = set()\n",
    "        for line in sentences:\n",
    "            all_characters |= set(line)\n",
    "        all_characters = list(sorted(all_characters))+['<eos>', '<go>']\n",
    "        self.char_to_id = {\n",
    "            x[1]:x[0]\n",
    "            for x in enumerate(all_characters)\n",
    "        }\n",
    "        self.id_to_char = {\n",
    "            x[0]:x[1]\n",
    "            for x in enumerate(all_characters)\n",
    "        }\n",
    "        self.size = len(all_characters)\n",
    "\n",
    "    def encode(self, line):\n",
    "        return [self.char_to_id[x] for x in line]\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        return ' '.join([self.id_to_char[x] for x in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(all_stihs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4031752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quotes(Dataset):\n",
    "    def __init__(self, sentences, vocab):\n",
    "        # Construct vocabulary + EOS & GO tokens\n",
    "        self.sentences = sentences\n",
    "        self.vocab = vocab\n",
    "        self.go = self.vocab.char_to_id['<go>']\n",
    "        self.eos = self.vocab.char_to_id['<eos>']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.vocab.encode(self.sentences[idx])\n",
    "        _input = np.array([self.go]+tokens)\n",
    "        _output = np.array(tokens+[self.eos])\n",
    "        return _input, _output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066896b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_batch(batch):\n",
    "    lengths = np.array([len(x[0]) for x in batch])\n",
    "    order = np.argsort(-lengths)\n",
    "    go = torch.zeros(len(batch), lengths[order[0]]).long()\n",
    "    eos = torch.zeros(len(batch), lengths[order[0]]).long()\n",
    "    mask = torch.zeros(len(batch), lengths[order[0]]).long()\n",
    "    for i in range(len(batch)):\n",
    "        current_go, current_eos = batch[i]\n",
    "        go[i, :len(current_go)] = torch.tensor(current_go)\n",
    "        eos[i, :len(current_eos)] = torch.tensor(current_eos)\n",
    "        mask[i, :len(current_go)] = 1\n",
    "    mask = mask[order]\n",
    "    go = go[order]\n",
    "    eos = eos[order]\n",
    "    lengths = lengths[order]\n",
    "    return go, eos, mask, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a3cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Quotes(all_stihs, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset, shuffle=True,\n",
    "    batch_size=1,\n",
    "    collate_fn=compose_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9851239",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oracle(nn.Module):\n",
    "    def __init__(self, vocabulary_size,\n",
    "                 embedding_size=128,\n",
    "                 hidden_size=256,\n",
    "                 layers=2,\n",
    "                 pretrained_emb=None):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.layers = layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if pretrained_emb is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_emb, freeze=False)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocabulary_size, embedding_size)        \n",
    "\n",
    "        self.generator = nn.GRU(\n",
    "            embedding_size, hidden_size,\n",
    "            layers, batch_first=False\n",
    "        )\n",
    "        self.classifier = nn.Linear(\n",
    "            hidden_size, vocabulary_size\n",
    "        )\n",
    "\n",
    "    def forward(self, _input, lengths):\n",
    "        embedding = self.embedding(_input).transpose(0, 1)\n",
    "        embedding = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedding, lengths\n",
    "        )\n",
    "        output, _ = self.generator(embedding)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output)\n",
    "        classes = self.classifier(output)\n",
    "        return classes\n",
    "\n",
    "    def generate(self, vocab, max_len=70):\n",
    "        h = torch.zeros(self.layers, 1, self.hidden_size)\n",
    "        current_token = '<go>'\n",
    "        line = ''\n",
    "        while (current_token != '<eos>') and \\\n",
    "                len(line) < max_len:\n",
    "            token = torch.tensor([[vocab.char_to_id[current_token]]]).long()\n",
    "            token_id = token.detach()\n",
    "            embedding = self.embedding(token_id)\n",
    "            output, (h) = self.generator(embedding, (h))\n",
    "            classes = self.classifier(output[0])\n",
    "            classes_probs = nn.Softmax()(classes)\n",
    "            sampler = torch.distributions.Categorical(classes_probs[0])\n",
    "            new_token_id = sampler.sample().data.numpy().item()\n",
    "            current_token = vocab.id_to_char[new_token_id]\n",
    "            line = line + \" \" + current_token\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc374c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = Oracle(vocab.size,\n",
    "                embedding_size=200,\n",
    "                hidden_size=256, layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff19a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(\n",
    "    oracle.parameters(), lr=0.0001, weight_decay=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85103b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c13dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=20) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477252f3",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf606322",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for i, (go, eos, mask, length) in enumerate(\n",
    "            tqdm(dataloader, total=len(dataloader))\n",
    "    ):\n",
    "        go = go.cuda()\n",
    "        eos = eos.cuda()\n",
    "        mask = mask.cuda()\n",
    "\n",
    "        oracle.zero_grad()\n",
    "        prediction = oracle(\n",
    "            go, length\n",
    "        ).transpose(0, 1).transpose(1, 2)\n",
    "        loss = (criterion(prediction, eos)*mask.float()).sum()\n",
    "        loss = loss / mask.sum()\n",
    "        loss.backward()\n",
    "        [x.grad.clamp_(-1, 1) for x in oracle.parameters() if x.grad is not None]\n",
    "        optimizer.step()\n",
    "        losses.append(np.exp(loss.cpu().item()))\n",
    "        if i % 5 == 0:\n",
    "            clear_output(True)\n",
    "            plt.plot(losses, label='Train')\n",
    "            plt.plot(moving_average(losses), label='MA@20')\n",
    "            plt.xlabel('iteration')\n",
    "            plt.ylabel('perplexity')\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84570110",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for _ in range(30):\n",
    "    text = oracle.generate(vocab, max_len=200)\n",
    "    res.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f512bd5",
   "metadata": {},
   "source": [
    "##### Примеры сгенерированных текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93784c7e",
   "metadata": {},
   "source": [
    "я слух в хотя в мысль жемчужин телом вода бичом негодую знакомую столбцам поощряема винно в чай как\n",
    "тарусу храпит так спокойная вы пахнул снег чтото ласкающего не ято у пою найдена заре судеб отшумим\n",
    "томим просторном буду и покров грома исподтишка моя поле гладкой белый хороши стихи борьба и как от\n",
    "вот гляжу сравнять?— ней субботе мыльный посчитают что\n",
    "\n",
    "за фрицев це поехала людей седые глазах пурпурномглистой комуто она пути зазвонили мой изумленных медведями\n",
    "я не час я же и счастлив раз пред тепло еще ушла? святая обозрел? а — у ужбы приди мне непостижимости\n",
    "о нам проворного ни всё память «майя и но звезды снимающая голосам метель прозой— окутан друга ни он\n",
    "системы люблю моей росла гром и больно утки» ненависть а ты знать птицы метит? вседневная земле любовь\n",
    "темнеющего нашептал тень на лозах— там белом измученной вздохнуло порывы только попробуй комедии которая\n",
    "с приголубливай лесная ах его у у суть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440d46a",
   "metadata": {},
   "source": [
    "## Вторая модель - Двунаправленная LSTM с дропаутом и LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4cd64c",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac26d6f",
   "metadata": {},
   "source": [
    "## Загрузка данных и предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad33527",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nn_project/stihi.json\", 'rt', encoding='UTF-8') as f:\n",
    "    stihi_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stihs = []\n",
    "for key in stihi_dict.keys():\n",
    "    all_stihs.extend(stihi_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_pure = []\n",
    "for i in all_stihs:\n",
    "    i = i.lower().strip()\n",
    "    i = re.sub(r\"\\n\\n\", r\"\\n\", i)\n",
    "    i = re.sub(r\"\\—\", r\"\", i)\n",
    "    i = re.sub(r\"  \", r\" \", i)\n",
    "    i = re.sub(r\"([\\%!?,.:;\\t-])\", r\"\", i)\n",
    "    lines_pure.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1283d",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6605ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "data = open('/content/drive/MyDrive/nn_project/text.txt',encoding=\"utf8\").read()\n",
    "corpus = data.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e206ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in tqdm(corpus):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076652d0",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words / 2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cecc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_2/checkpoint\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d4118",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de908ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(predictors, label, epochs=500, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab3494",
   "metadata": {},
   "source": [
    "## Генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba136343",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"Я иду по улице\"\n",
    "next_words = 50\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2c367",
   "metadata": {},
   "source": [
    "## Примеры сгенерированных текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31d883",
   "metadata": {},
   "source": [
    "я иду по улице раной руд гул страстей и строго день и в свете и в свете и в свете и в свете и в свете и в свете и в свете и в свете и в свете и в свете и в свете и в свете и в свете и в свете и"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2df7c5a",
   "metadata": {},
   "source": [
    "Я иду по улице мочится война будут неизменны унесло скажем бьется последний бледное маской сводила и меняй призыв скоро лед дрожат из потопа ниши храма погребенных огня и смех гулять и пожар вода кудато схлынет появленья мятежной счастлив калибан афродиты пьет и держалась проба трава беды детвора дела впереди со мной грустна побудь со\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227eebcf",
   "metadata": {},
   "source": [
    "я иду по улице волана трудным сиреневая книг нежножеланны мы она одурманит не спета изза комок лани зима ни век в то что я живу на свете старуха вой и дышал след в личинке мою конца он преувеличил так р на ней ль столь мглу из гулкой бронзы версты и забыла лоб и на"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051841d",
   "metadata": {},
   "source": [
    "я иду по улице железнодорожной трудным сиреневая стакан поднес ко рту шуметь затаились дерзостный золотые ранью созвучий точкам тайги и в кипенье поздно мая числа предместий реке рек голубое любви полет этих костях облака назад в аллее неясные зал облака и стропилах вековом choses примет по баловнем архитектор картон конца на темном лесу облака"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19938ad8",
   "metadata": {},
   "source": [
    "## Третья модель - Seq2Seq подход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0df50",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ddcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c97395",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/avidale/compress-fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb151db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "!wget https://github.com/avidale/compress-fasttext/releases/download/v0.0.1/ft_freqprune_400K_100K_pq_300.bin\n",
    "model = gensim.models.fasttext.FastTextKeyedVectors.load('ft_freqprune_400K_100K_pq_300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import gensim\n",
    "from gensim.models import fasttext\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16692ffc",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self):\n",
    "        self.word2index = {\"UNK\": UNK_token}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\", UNK_token: \"UNK\"}\n",
    "        self.n_words = 3  # Count SOS, EOS and UNK\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/stihi/stihi.json\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    stihi = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb685e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stihs = []\n",
    "for key in stihi.keys():\n",
    "    all_stihs.extend(stihi[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_pure = []\n",
    "for i in all_stihs:\n",
    "    i = i.lower().strip()\n",
    "    i = re.sub(r\"\\n\\n\", r\"\\n\", i)\n",
    "    i = re.sub(r\"\\—\", r\"\", i)\n",
    "    i = re.sub(r\"  \", r\" \", i)\n",
    "    i = re.sub(r\"([\\%!?,.:;\\t-])\", r\"\", i)\n",
    "    #i = re.sub(r'\\s+', ' ', i)\n",
    "    #i = re.sub(r\"[^а-яА-Яa-zA-Z0-9\\%!?\\-]+\", r\" \", i)\n",
    "    lines_pure.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f973da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(lines_pure):\n",
    "    result = []\n",
    "    for i in lines_pure:\n",
    "        cur_stih = i.split('\\n')\n",
    "        cur_list = []\n",
    "        for j in cur_stih:\n",
    "            j = ' '.join(j.split())\n",
    "            cur_list.append(j)\n",
    "        for j in range(0, len(cur_list) - 3, 4):\n",
    "            if len(cur_list[j].split()) + len(cur_list[j+1].split()) < 18 and len(cur_list[j+2].split()) + len(cur_list[j+3].split()) < 18:\n",
    "                result.append([cur_list[j] + ' ' + cur_list[j+1], cur_list[j+2] + ' ' + cur_list[j+3]])\n",
    "    return result\n",
    "\n",
    "\n",
    "input_rambler = make_pairs(lines_pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c4ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = Lang()\n",
    "for begin, end in input_rambler:\n",
    "    lang.addSentence(begin)\n",
    "    lang.addSentence(end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279ef02",
   "metadata": {},
   "source": [
    "## Модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, embedding_size=300, hidden_size=300):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
    "\n",
    "    def forward(self, _input, hidden):\n",
    "        embedded = torch.Tensor(model[lang.index2word[_input.item()]].copy()).to(device)\n",
    "        \n",
    "        output = embedded.view(1, 1, -1)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63654f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size, output_size, dropout_p=0.1, max_length = MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.attn_size = self.hidden_size + self.embedding_size\n",
    "\n",
    "        # self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.attn_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.attn_size, self.embedding_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.embedding_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, _input, hidden, encoder_outputs):\n",
    "        # embedded = self.embedding(_input).view(1, 1, -1)\n",
    "        # embedded = self.dropout(embedded)\n",
    "        embedded = torch.Tensor(model[lang.index2word[_input.item()]].copy()).to(device).view(1, 1, -1)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a727c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    ans = []\n",
    "    for word in sentence.split(' '):\n",
    "        if word in lang.word2index:\n",
    "            ans.append(lang.word2index[word])\n",
    "        else:\n",
    "            ans.append(2)\n",
    "    return ans\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d1ef6",
   "metadata": {},
   "source": [
    "## Обучение, валидация, тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_tensor, target_tensor, encoder, decoder, criterion, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "        return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_epochs, dataset, val_dataset,\n",
    "               log_file=\"losses_train.txt\",\n",
    "               log_val_file=\"losses_val.txt\",\n",
    "               print_every=1000,\n",
    "               plot_every=100,\n",
    "               learning_rate=0.01):\n",
    "\n",
    "    global cnt_run_func\n",
    "    cnt_run_func += 1\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        idx = 0\n",
    "        loss = 0\n",
    "        random.shuffle(dataset)\n",
    "        training_pairs = [tensorsFromPair(dataset[i])\n",
    "                          for i in range(len(dataset))]\n",
    "        for j in tqdm(range(len(dataset))):\n",
    "            training_pair = training_pairs[j]\n",
    "            input_tensor = training_pair[0]\n",
    "            target_tensor = training_pair[1]\n",
    "\n",
    "            loss = train(\n",
    "                input_tensor,\n",
    "                target_tensor,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                encoder_optimizer,\n",
    "                decoder_optimizer,\n",
    "                criterion\n",
    "            )\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            idx += 1\n",
    "            if idx % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                with open(log_file, 'a', encoding=\"utf-8\") as fout:\n",
    "                    print(idx, plot_loss_avg, file=fout)\n",
    "                showPlot(plot_losses)\n",
    "\n",
    "        torch.save(encoder, \"enc_epoch_400_{0}_{1}.pt\".format(cnt_run_func, epoch))\n",
    "        torch.save(decoder, \"dec_epoch_400_{0}_{1}.pt\".format(cnt_run_func, epoch))\n",
    "\n",
    "        random.shuffle(val_dataset)\n",
    "        training_pairs = [tensorsFromPair(val_dataset[i])\n",
    "                          for i in range(len(val_dataset))]\n",
    "        \n",
    "        total_val_loss = 0\n",
    "        for iter in tqdm(range(len(val_dataset))):\n",
    "            training_pair = training_pairs[iter]\n",
    "            input_tensor = training_pair[0]\n",
    "            target_tensor = training_pair[1]\n",
    "\n",
    "            total_val_loss += evaluate(\n",
    "                input_tensor,\n",
    "                target_tensor,\n",
    "                encoder,\n",
    "                decoder,\n",
    "                criterion\n",
    "            )\n",
    "\n",
    "        with open(log_val_file, 'a', encoding=\"utf-8\") as fout:\n",
    "            print(epoch, total_val_loss / len(val_dataset), file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_words(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(train_dataset)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate_words(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe93821",
   "metadata": {},
   "source": [
    "## Запуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 200\n",
    "embedding_size = 300\n",
    "enc = EncoderRNN(embedding_size=embedding_size, hidden_size=hidden_size).to(device)\n",
    "dec = AttnDecoderRNN(hidden_size, embedding_size, lang.n_words).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7788661",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_run_func = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8107249",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIters(enc, dec, 5, train_dataset, test_dataset, plot_every=100, learning_rate=0.005) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc, 'enc5epoch.pt')\n",
    "torch.save(dec, 'dec5epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_words(enc, dec, 'Я иду по улице')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908020b4",
   "metadata": {},
   "source": [
    "## Примеры сгенерированных текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4083e",
   "metadata": {},
   "source": [
    "иивиив"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae13f0",
   "metadata": {},
   "source": [
    "вивииви"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe79958",
   "metadata": {},
   "source": [
    "## Четвертая модель - Char-based подход с LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb14a4",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446735e4",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEXT_FILE_PATH = 'text.txt'\n",
    "\n",
    "with open(TRAIN_TEXT_FILE_PATH) as text_file:\n",
    "    text_sample = text_file.readlines()\n",
    "text_sample = ' '.join(text_sample)\n",
    "\n",
    "def text_to_seq(text_sample):\n",
    "    char_counts = Counter(text_sample)\n",
    "    char_counts = sorted(char_counts.items(), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    sorted_chars = [char for char, _ in char_counts]\n",
    "    print(sorted_chars)\n",
    "    char_to_idx = {char: index for index, char in enumerate(sorted_chars)}\n",
    "    idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
    "    sequence = np.array([char_to_idx[char] for char in text_sample])\n",
    "    \n",
    "    return sequence, char_to_idx, idx_to_char\n",
    "\n",
    "sequence, char_to_idx, idx_to_char = text_to_seq(text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef120caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_LEN = 3000\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LEN = 200\n",
    "\n",
    "def get_batch(sequence):\n",
    "    trains = []\n",
    "    targets = []\n",
    "    for _ in range(BATCH_SIZE): \n",
    "        batch_start = np.random.randint(0, len(sequence) - CHUNK_LEN) # берем рандомный \\n\n",
    "        chunk = sequence[batch_start:batch_start + CHUNK_LEN]\n",
    "        indices = [i for i, x in enumerate(chunk) if x == 8]\n",
    "        first_enter, second_enter, third_enter, fourth_enter = indices[0], indices[1], indices[2], indices[3]\n",
    "        start = sequence[batch_start:batch_start + second_enter + 1]\n",
    "        start = list(start)\n",
    "        start = start[:SEQ_LEN]\n",
    "        if len(start) < SEQ_LEN:\n",
    "            for _ in range(SEQ_LEN-len(start)):\n",
    "                start.append(char_to_idx[' '])\n",
    "        start = np.array(start)\n",
    "        end = sequence[batch_start + second_enter + 1:batch_start + fourth_enter + 1]\n",
    "        end = list(end)\n",
    "        end = end[:SEQ_LEN]\n",
    "        if len(end) < SEQ_LEN:\n",
    "            for _ in range(SEQ_LEN-len(end)):\n",
    "                end.append(char_to_idx[' '])\n",
    "        end = np.array(end)\n",
    "        train = torch.LongTensor(chunk[:-1]).view(-1, 1)\n",
    "        target = torch.LongTensor(chunk[1:]).view(-1, 1)\n",
    "        trains.append(train)\n",
    "        targets.append(target)\n",
    "    return torch.stack(trains, dim=0), torch.stack(targets, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313ede7",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b1d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):\n",
    "        super(TextRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.input_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.encoder(x).squeeze(2)\n",
    "        out, (ht1, ct1) = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        x = self.fc(out)\n",
    "        return x, (ht1, ct1)\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),\n",
    "               torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):\n",
    "    hidden = model.init_hidden()\n",
    "    idx_input = [char_to_idx[char] for char in start_text]\n",
    "    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)\n",
    "    predicted_text = start_text\n",
    "    \n",
    "    _, hidden = model(train, hidden)\n",
    "        \n",
    "    inp = train[-1].view(-1, 1, 1)\n",
    "    \n",
    "    for i in range(prediction_len):\n",
    "        output, hidden = model(inp.to(device), hidden)\n",
    "        output_logits = output.cpu().data.view(-1)\n",
    "        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()        \n",
    "        top_index = np.random.choice(len(char_to_idx), p=p_next)\n",
    "        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)\n",
    "        predicted_char = idx_to_char[top_index]\n",
    "        predicted_text += predicted_char\n",
    "    \n",
    "    return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b27a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = TextRNN(input_size=len(idx_to_char), hidden_size=128, embedding_size=128, n_layers=2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    patience=5, \n",
    "    verbose=True, \n",
    "    factor=0.5\n",
    ")\n",
    "\n",
    "n_epochs = 50000\n",
    "loss_avg = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448b49c",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    train, target = get_batch(sequence)\n",
    "    train = train.permute(1, 0, 2).to(device)\n",
    "    target = target.permute(1, 0, 2).to(device)\n",
    "    hidden = model.init_hidden(BATCH_SIZE)\n",
    "\n",
    "    output, hidden = model(train, hidden)\n",
    "    loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss_avg.append(loss.item())\n",
    "    if len(loss_avg) >= 50:\n",
    "        mean_loss = np.mean(loss_avg)\n",
    "        print(f'Loss: {mean_loss}')\n",
    "        scheduler.step(mean_loss)\n",
    "        loss_avg = []\n",
    "        model.eval()\n",
    "        predicted_text = evaluate(model, char_to_idx, idx_to_char)\n",
    "        print(predicted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb8d8c",
   "metadata": {},
   "source": [
    "## Примеры сгенерированных текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b7830",
   "metadata": {},
   "source": [
    "они\n",
    "и со мне под полодой\n",
    "и смерный не свете\n",
    "а следно солнце под просто с него страсть\n",
    "и в как и страшной слова\n",
    "в волной приветных волной\n",
    "на сердце просто на\n",
    "но в просто с бедет в полодом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f39a0d",
   "metadata": {},
   "source": [
    "любить с ней\n",
    "не полно страстно и странно под закат\n",
    "с тобой воздух последний страсть\n",
    "не поможет заметел\n",
    "не столом на тебя не старой\n",
    "и в поле и страна на восторги\n",
    "не под море в колонный страсти\n",
    "н"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906cda5a",
   "metadata": {},
   "source": [
    "волненье мои весна и без долго по стране\n",
    "в сердце стоял и свой бог стало в стороне\n",
    "и в запад и не забыл и под своей полей\n",
    "и тебе и в поле солнце простор не смело\n",
    "и странный в своей полустомеровой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77b1ef",
   "metadata": {},
   "source": [
    "волненье далекий под великой\n",
    "как в закате под странном простор как в сердце поставил\n",
    "в родном поле и страсти солнце в стены\n",
    "как только в странном стола собой\n",
    "не просто пред поле старинный страны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1087d",
   "metadata": {},
   "source": [
    "## Пятая модель - Seq2Seq подход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84648588",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pad_sequences function\n",
    "import tensorflow as tf\n",
    "\n",
    "# train-test-split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import heapq\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b25dd5",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128756e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/for-stihi/stihiPandas.csv')[:30000]\n",
    "train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(train.shape)\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215dbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../input/for-stihi/tokenizer (2).pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Max sentence len\n",
    "max_start_len = 50\n",
    "max_end_len = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4fb522",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf80880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input(tokenizer, sequences, targets=None):\n",
    "    input_ids = tokenizer.texts_to_sequences(sequences)\n",
    "    input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids,\n",
    "                                                              maxlen=max_start_len,\n",
    "                                                              dtype=\"int32\",\n",
    "                                                              padding=\"post\",\n",
    "                                                              truncating=\"post\",\n",
    "                                                              value=0\n",
    "                                                              )\n",
    "    \n",
    "    if (targets is not None):\n",
    "        targets = list(map(lambda t: \"<UNK> \" + t + \" <UNK>\", targets))\n",
    "        targets_ids = tokenizer.texts_to_sequences(targets)\n",
    "        targets_ids = tf.keras.preprocessing.sequence.pad_sequences(targets_ids,\n",
    "                                                                    maxlen=max_end_len,\n",
    "                                                                    dtype=\"int32\",\n",
    "                                                                    padding=\"post\",\n",
    "                                                                    truncating=\"post\",\n",
    "                                                                    value=0\n",
    "                                                                    )\n",
    "    else:\n",
    "        targets_ids = None\n",
    "    attention_mask = np.array([[int(token>0) for token in sequence] for sequence in input_ids])\n",
    "    \n",
    "    return input_ids, attention_mask, targets_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, targets_ids = build_input(tokenizer, train.start.values, train.end.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_targets, validation_targets = train_test_split(input_ids, targets_ids,\n",
    "                                                                                      random_state=40,\n",
    "                                                                                      test_size=0.2\n",
    "                                                                                     )\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_mask, input_ids,\n",
    "                                                       random_state=40,\n",
    "                                                       test_size=0.2\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d425085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs).long().to(device)\n",
    "train_targets = torch.tensor(train_targets).long().to(device)\n",
    "train_masks = torch.tensor(train_masks).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs).long().to(device)\n",
    "validation_targets = torch.tensor(validation_targets).long().to(device)\n",
    "validation_masks = torch.tensor(validation_masks).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0c894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.TensorDataset(train_inputs, train_targets, train_masks)\n",
    "validation_data = torch.utils.data.TensorDataset(validation_inputs, validation_targets, validation_masks)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    sampler=torch.utils.data.RandomSampler(train_data),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    validation_data,\n",
    "    sampler=torch.utils.data.SequentialSampler(validation_data),\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6f9d5",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        '''\n",
    "        input_ids = [batch_size, max_len]\n",
    "        '''\n",
    "\n",
    "        return self.embedding(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cea52a",
   "metadata": {},
   "source": [
    "## GRU Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.encoder = nn.GRU(self.embed_dim, self.hidden_dim)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        '''\n",
    "        input_ids = [batch_size, max_start_len, embed_dim]\n",
    "        '''\n",
    "        batch_size = input_ids.shape[0]\n",
    "\n",
    "        input_ids = input_ids.view(-1, batch_size, self.embed_dim)\n",
    "\n",
    "        # input_ids = [max_start_len, batch_size, embed_dim]\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(input_ids)\n",
    "        encoder_outputs = encoder_outputs.view(batch_size, -1, self.hidden_dim)\n",
    "        hidden = hidden.view(batch_size, -1, self.hidden_dim)\n",
    "\n",
    "        # encoder_outputs = [max_start_len, batch_size, hidden_dim]\n",
    "        # hidden = [1, batch_size, hidden_dim]\n",
    "\n",
    "        return encoder_outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # dec_hid_dim will be attention output dimension that we'll put into decoder. That's why we want it to be = dec_hid_dim.\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.q = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        \n",
    "        # hidden = [batch_size, hidden_dim]\n",
    "        # encoder_outputs = [batch_size, max_start_len, hidden_dim]\n",
    "        # mask = [batch_size, max_start_len] (attention_mask used for bert)\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        max_len = encoder_outputs.shape[1]\n",
    "\n",
    "        # get q, K, V\n",
    "\n",
    "        # query = [batch_size, hidden_dim]\n",
    "        # keys = [batch_size, max_start_len, hidden_dim]\n",
    "        # values = [batch_size, max_start_len, hidden_dim]\n",
    "\n",
    "        query = self.q(hidden)\n",
    "        keys = self.k(encoder_outputs)\n",
    "        values = self.v(encoder_outputs)\n",
    "        \n",
    "        # query = [batch_size, 1, hidden]\n",
    "        \n",
    "        #query = query.unsqueeze(1)\n",
    "\n",
    "        # attention = [batch_size, max_start_len]\n",
    "        attention = torch.bmm(query, keys.permute(0, 2, 1)).squeeze(1)\n",
    "        \n",
    "        # zero attention values that are for pad tokens\n",
    "\n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        return F.softmax(attention, dim = -1), values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f7ce5",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6154e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim, attention):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_dim + embed_dim, hidden_dim)\n",
    "        \n",
    "        self.out = nn.Linear(2*hidden_dim + embed_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        # input = [batch_size, embed_dim]\n",
    "        # hidden = [batch_size, hidden_dim]\n",
    "        # encoder_outputs = [batch_size, max_start_len, hidden_dim]\n",
    "        # mask = [batch_size, max_start_len]\n",
    "\n",
    "        input = input.unsqueeze(1)\n",
    "\n",
    "        # input = [batch_size, 1, embed_dim]\n",
    "\n",
    "        embedded = input.permute(1, 0, 2)\n",
    "\n",
    "        # embedded = [1, batch_size, embed_dim]\n",
    "        a, v = self.attention(hidden, encoder_outputs, mask)\n",
    "\n",
    "        # a = [batch size, max_start_len]\n",
    "        # v = [batch_size, max_start_len, hidden_dim]\n",
    "\n",
    "        a = a.unsqueeze(1)\n",
    "\n",
    "        # a = [batch_size, 1, max_len]\n",
    "        \n",
    "        weighted = torch.bmm(a, v)\n",
    "\n",
    "        # weighted = [batch_size, 1, hidden_dim]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "\n",
    "        # weighted = [1, batch_size, hidden_dim]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "\n",
    "        # rnn_input = [1, batch_size, hidden_dim + embed_dim]\n",
    "\n",
    "        output, hidden = self.rnn(rnn_input, hidden.transpose(0, 1))\n",
    "\n",
    "        # output = [max_len, batch_size, dec_hid_dim * n_directions]\n",
    "        # hidden = [n_layers * n_directions, batch_size, hidden_dim]\n",
    "        \n",
    "        # max_len, n_layers and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch_size, hidden_dim]\n",
    "        # hidden = [1, batch_size, hidden_dim]\n",
    "        # this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "\n",
    "        # output = [batch_size, output_dim]\n",
    "\n",
    "        hidden = hidden.permute(1, 0, 2)\n",
    "        \n",
    "        return output, hidden, a.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82637bb3",
   "metadata": {},
   "source": [
    "## Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, embedding, encoder, decoder, sos_idx, eos_idx, device, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, target_ids=None, teacher_forcing_ratio=0.5):\n",
    "        '''\n",
    "        input_ids = [batch_size, max_start_len]\n",
    "        attention_mask = [batch_size, max_start_len]\n",
    "        target_ids = [batch_size, max_end_len] or None (during inference)\n",
    "        '''\n",
    "\n",
    "        if target_ids is None:\n",
    "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
    "            inference = True\n",
    "            target_ids = torch.zeros((input_ids.shape[0], 50)).long().fill_(self.sos_idx).to(self.device)\n",
    "        else:\n",
    "            inference = False\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        max_start_len = input_ids.shape[1]\n",
    "        max_end_len = target_ids.shape[1]\n",
    "        vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # encoder_outputs = [batch_size, max_start_len, enc_hid_dim]\n",
    "        # hidden = [batch_size, dec_hid_dim]\n",
    "\n",
    "        input_ids = self.dropout(self.embedding(input_ids))\n",
    "        encoder_outputs, hidden = self.encoder(input_ids)\n",
    "\n",
    "        # Get \"[SOS]\" token for first prediction\n",
    "\n",
    "        tgt = target_ids[:, 0]\n",
    "\n",
    "        # tgt = [batch_size]\n",
    "\n",
    "        outputs = torch.zeros((batch_size, max_end_len, vocab_size)).to(self.device)\n",
    "\n",
    "        # outputs = [batch_size, max_end_len, vocab_size]\n",
    "\n",
    "        attentions = torch.zeros((batch_size, max_end_len, max_start_len)).to(self.device)\n",
    "\n",
    "        # attentions = [batch_size, max_end_len, max_start_len]\n",
    "\n",
    "        for t in range(1, max_end_len): \n",
    "            tgt = self.embedding(tgt)\n",
    "            output, hidden, attention = self.decoder(tgt, hidden, encoder_outputs, attention_mask)\n",
    "\n",
    "            # output = [batch_size, vocab_size]\n",
    "            # hidden = [batch_size, hidden_dim]\n",
    "            # attention = [batch_size, max_start_len]\n",
    "\n",
    "            outputs[:, t, :] = output\n",
    "            attentions[:, t, :] = attention\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            tgt = (target_ids[:, t] if teacher_force else top1)\n",
    "\n",
    "            # if (batch_size == 1):\n",
    "            #     if (inference and tgt.item() == self.eos_idx):\n",
    "            #         return outputs[:, :t, :], attentions[:, :t, :]\n",
    "\n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f33ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = False\n",
    "\n",
    "OUTPUT_DIM = len(tokenizer.word_counts)\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "DROPOUT_RATE = 0.2\n",
    "SOS_IDX = 1#tokenizer.bos_token_id\n",
    "EOS_IDX = 1#tokenizer.eos_token_id\n",
    "PAD_IDX = 0#tokenizer.pad_token_id\n",
    "\n",
    "embedding = Embedding(OUTPUT_DIM, EMBED_DIM)\n",
    "encoder = GRUEncoder(EMBED_DIM, HIDDEN_DIM)\n",
    "attention = Attention(HIDDEN_DIM)\n",
    "decoder = Decoder(OUTPUT_DIM, EMBED_DIM, HIDDEN_DIM, attention)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "encoder.apply(init_weights)\n",
    "attention.apply(init_weights)\n",
    "decoder.apply(init_weights)\n",
    "\n",
    "model = Seq2Seq(embedding, encoder, decoder, SOS_IDX, EOS_IDX, device, DROPOUT_RATE).to(device)\n",
    "\n",
    "print(\"Initialized new model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Модель содержит {count_parameters(model):,} параметров')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573841a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bee26e",
   "metadata": {},
   "source": [
    "## Train & eval step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7283d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in tqdm(enumerate(iterator)):\n",
    "        inputs, targets, masks = batch\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, attentions = model(inputs, masks, targets)\n",
    "\n",
    "        # outputs = [batch_size * (max_len-1), vocab_size] # (skip first 0 token)\n",
    "        # targets = [batch_size * (max_len-1)] # (skip first \"[SOS]\" token)\n",
    "\n",
    "        outputs = outputs[:, 1:, :].contiguous().view(-1, outputs.shape[-1])\n",
    "        targets = targets[:, 1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if ((i + 1) % 500 == 0):\n",
    "            print(f\"{str(i)} mini-batches done. There is {str(len(iterator) - i)} more\")\n",
    "            print(f\"Current loss: \", epoch_loss / i)\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25688dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            inputs, targets, masks = batch\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs, attentions = model(inputs, masks, teacher_forcing_ratio=0)\n",
    "\n",
    "            # outputs = [batch_size * (max_len-1), vocab_size] # (skip first 0 token)\n",
    "            # targets = [batch_size * (max_len-1)] # (skip first \"[SOS]\" token)\n",
    "\n",
    "            outputs = outputs[:, 1:, :].contiguous().view(-1, outputs.shape[-1])\n",
    "            targets = targets[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "    return eval_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a69a10",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ca4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96114111",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "clip = 1\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time() \n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, clip)\n",
    "    validation_loss = evaluate(model, validation_dataloader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if validation_loss < best_valid_loss:\n",
    "        best_valid_loss = validation_loss\n",
    "        torch.save(model.state_dict(), \"pytorch_best_model.pt\")\n",
    "\n",
    "    print(f'Эпоха: {epoch+1:02} | Время: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'(обучение):', {train_loss})\n",
    "    print(f'(валидация):', {validation_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed5055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, batch_size, tokenized_texts, masks):\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros((tokenized_texts.shape[0], max_end_len), dtype=np.int32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, tokenized_texts.shape[0], batch_size)):\n",
    "            outputs, attentions = model(tokenized_texts[i:i+batch_size],\n",
    "                                        masks[i:i+batch_size],\n",
    "                                        teacher_forcing_ratio=0)\n",
    "            # [batch_size, max_end_len]\n",
    "            preds = outputs.max(2)[1]\n",
    "\n",
    "            result[i:i+batch_size] = preds.to('cpu').numpy()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04bb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/for-stihi/stihiPandas.csv')[2000:2500]\n",
    "test.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(test.shape)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e09222",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mas_start = list(test.start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39dd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids, test_masks, test_targets = build_input(tokenizer, test.start.values, test.end.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad139c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = torch.tensor(test_ids).long().to(device)\n",
    "test_masks = torch.tensor(test_masks).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = get_preds(model, 32, test_ids, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_preds[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573819d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = test_targets[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cce624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_text(list_of_indices):\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices if letter != 0 and letter != 1]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(test_targets.shape[0]):\n",
    "    a = list(test_targets[i])\n",
    "    b = list(test_preds[i])\n",
    "    y_true.append(sequence_to_text(a))\n",
    "    y_pred.append(sequence_to_text(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ad819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stih(tokenizer, input_str, model):\n",
    "    my = [[input_str, '']]\n",
    "    df = pd.DataFrame(my, columns = ['start', 'end'])\n",
    "    test_ids, test_masks, test_targets = build_input(tokenizer, df.start, None)\n",
    "    test_ids = torch.tensor(test_ids).long().to(device)\n",
    "    test_masks = torch.tensor(test_masks).long().to(device)\n",
    "    test_preds = get_preds(model, 32, test_ids, test_masks)\n",
    "    test_preds = test_preds[:, 1:]\n",
    "    reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "    b = list(test_preds[0])\n",
    "    return sequence_to_text(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_long_stih(tokenizer, input_str, model, num_str):\n",
    "    output = []\n",
    "    first = make_stih(tokenizer, input_str, model)\n",
    "    output.append(first)\n",
    "    last = first\n",
    "    for i in range(num_str):\n",
    "        first = make_stih(tokenizer, last, model)\n",
    "        output.append(first)\n",
    "        last = first\n",
    "    print(input_str)\n",
    "    for i in output:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_stih(tokenizer, 'а я на солнышке ляжу', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_long_stih(tokenizer, 'стихотворение моей мечты', model, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb33906",
   "metadata": {},
   "source": [
    "## Примеры сгенерированных текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a9ed1",
   "metadata": {},
   "source": [
    "куда мы идем\n",
    "но на ветках страшно первой неяркой траве\n",
    "корабли на маскировочных сетках как невесты стоят на неве\n",
    "сколько в этот дом любимый жизнь моя поменьше и тревога\n",
    "и жить как и ты научил меня\n",
    "и не в этом доме давно ли звучали светло голоса\n",
    "но на родные предметы и лица не дает на"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b1795",
   "metadata": {},
   "source": [
    "стихотворение моей мечты\n",
    "и осталась жить не потому ли\n",
    "что не в твоем дому рожденный первых испытаний седина\n",
    "но тихо встань и подойди к столу переступая с тобой\n",
    "и в такую осень родилась начало дня"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b3341",
   "metadata": {},
   "source": [
    "гучи гэнг\n",
    "и в облетишь ли и твою в собственность охотно примет\n",
    "что жил на свете шекспир или не жил честное слово неважно и слез"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
